{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6o1RNIYKyubMt2q+THX+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minoooo119/deeplearning_study/blob/main/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98%EB%A1%9C_%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94_%EB%94%A5%EB%9F%AC%EB%8B%9D_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🤩 다중 선형 회귀 구현 (3-3장)"
      ],
      "metadata": {
        "id": "eeda6Wz5JM8G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "13AtyMXG3vRx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvHzTmua4A_d",
        "outputId": "642de538-8d07-4173-bc97-e7256bc9abcb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b460aded0f0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$H(x)=w_1x_1+w_2x_2+w_3x_3+b$  \n",
        "처럼 단순 선형 회귀와 다르게 $x$개수가 3개임  \n",
        "**다중 선형 회귀 (Multivariable Linear Regression)**\n",
        "\n",
        "## ☑️ 파이토치로 구현하기"
      ],
      "metadata": {
        "id": "fZUXrBzY6pow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n"
      ],
      "metadata": {
        "id": "-i4sw0p64953"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이에 대해서 가중치, 절편 초기화\n"
      ],
      "metadata": {
        "id": "cy-1vENM7EVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 w와 편향 b 초기화\n",
        "w1 = torch.zeros(1, requires_grad=True)\n",
        "w2 = torch.zeros(1, requires_grad=True)\n",
        "w3 = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n"
      ],
      "metadata": {
        "id": "VArvO2A07DcV"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "가설, 비용 함수, 옵티마이저 선언 후 경사 하강법 1,000회 반복"
      ],
      "metadata": {
        "id": "gjuldXFeCsP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
        "#에포크 1번당 경사 하강법 1회\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad() #gradient 누적되기 때문에 매번 초기화 필요\n",
        "    cost.backward() #w1,w2,w3,b 기준으로 gradient 계산\n",
        "    optimizer.step() #이후 learning rate 곱하여 기존 가중치와 절편에서 빼준다.\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
        "        ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lubBBB6P7CAY",
        "outputId": "e694fe11-1378-4890-9972-cf8576a7dcda"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
            "Epoch  100/1000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost: 1.563628\n",
            "Epoch  200/1000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost: 1.497595\n",
            "Epoch  300/1000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost: 1.435044\n",
            "Epoch  400/1000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost: 1.375726\n",
            "Epoch  500/1000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost: 1.319507\n",
            "Epoch  600/1000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost: 1.266222\n",
            "Epoch  700/1000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost: 1.215703\n",
            "Epoch  800/1000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost: 1.167810\n",
            "Epoch  900/1000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost: 1.122429\n",
            "Epoch 1000/1000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ☑️ 벡터와 행렬 연산으로 바꾸기\n",
        "### 1️⃣ 벡터 연산으로\n",
        "* 위의 계산에서는 x가 3개 존재해서 직접 가정값 계산 가능\n",
        "* 1000개 이상이라면 힘들기 때문에 벡터 연산으로 진행\n",
        "$H(x)=w_1x_1+w_2x_2+w_3x_3$\n",
        "위 식을 벡터의 내적으로 표현\n",
        "\n",
        "  $\\begin{bmatrix}x_1&x_2&x_3\\\\ \\end{bmatrix}⋅\\begin{bmatrix}w_1\\\\w_2\\\\w_3\\\\ \\end{bmatrix}=\\begin{bmatrix}x_1w_1+x_2w_2+x_3w_3\\\\ \\end{bmatrix} $\n",
        "\n",
        "  로 표현할 수 있음\n",
        "\n",
        "\n",
        "### 2️⃣ 행렬 연산으로\n",
        "* y를 결정 짓는데 있어서 총 샘플이 5개라고 하고 특성이 3개가 있다고 하자 이때 가중치와 계산은 벡터의 연산으로 할 수 없음\n",
        "* 애초에 5×3 행렬과 3×1 행렬의 곱으로 5×1의 결과 y를 결정하게 된다.  \n",
        "\n",
        "  $\\begin{pmatrix}x_{11}&x_{12}&x_{13}\\\\x_{21}&x_{22}&x_{23}\\\\x_{31}&x_{32}&x_{33}\\\\x_{41}&x_{42}&x_{43}\\\\x_{51}&x_{52}&x_{53}\\\\\\end{pmatrix}$$\\begin{pmatrix}w_{1}\\\\w_{2}\\\\w_{3}\\\\\\end{pmatrix}$=$\\begin{pmatrix}x_{11}w_1+x_{12}w_2+x_{13}w_3\\\\x_{21}w_1+x_{22}w_2+x_{23}w_3\\\\x_{31}w_1+x_{32}w_2+x_{33}w_3\\\\x_{41}w_1+x_{42}w_2+x_{43}w_3\\\\x_{51}w_1+x_{52}w_2+x_{53}w_3\\\\ \\end{pmatrix}$\n",
        "\n",
        "  \n",
        "\n",
        "  * 행렬이용해서 다중 선형 회귀 계산 진행 ⬇️"
      ],
      "metadata": {
        "id": "g3UJYgd1Da7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
        "                               [93,  88,  93],\n",
        "                               [89,  91,  80],\n",
        "                               [96,  98,  100],\n",
        "                               [73,  66,  70]])\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
        "#특성 3개 5개의 샘플 5*3"
      ],
      "metadata": {
        "id": "p1La04rVDTWJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiouIAZHHy8H",
        "outputId": "5e1d972c-3f91-4657-d6e6-1301a8a8597b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치와 편향 선언\n",
        "W = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "#가중치는 3*1 벡터임 --> 각 특성에 대해서 가중치가 필요한 거니까 특성 수와 같아야함"
      ],
      "metadata": {
        "id": "uWlMsGqhH40r"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    # 편향 b는 브로드 캐스팅되어 각 샘플에 더해집니다.\n",
        "    hypothesis = x_train.matmul(W) + b\n",
        "    #가중치와 곱해줌\n",
        "    #위 부분이 행렬을 이용해서 개선된 부분\n",
        "\n",
        "    # cost 계산\n",
        "    #가설과 실제 값의 편차 제곱의 평균\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch%100==0:\n",
        "      print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
        "      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6WPiD1VIOIw",
        "outputId": "d4222871-8a8d-45f2-c6ec-1b754ba56bea"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 hypothesis: tensor([152.6685, 184.5856, 179.4857, 196.1604, 142.2285]) Cost: 0.192199\n",
            "Epoch  100/1000 hypothesis: tensor([152.6628, 184.5864, 179.4926, 196.1545, 142.2333]) Cost: 0.189211\n",
            "Epoch  200/1000 hypothesis: tensor([152.6572, 184.5872, 179.4994, 196.1487, 142.2380]) Cost: 0.186330\n",
            "Epoch  300/1000 hypothesis: tensor([152.6517, 184.5880, 179.5060, 196.1430, 142.2426]) Cost: 0.183563\n",
            "Epoch  400/1000 hypothesis: tensor([152.6464, 184.5889, 179.5125, 196.1374, 142.2472]) Cost: 0.180887\n",
            "Epoch  500/1000 hypothesis: tensor([152.6411, 184.5897, 179.5189, 196.1319, 142.2517]) Cost: 0.178310\n",
            "Epoch  600/1000 hypothesis: tensor([152.6359, 184.5905, 179.5251, 196.1266, 142.2561]) Cost: 0.175835\n",
            "Epoch  700/1000 hypothesis: tensor([152.6308, 184.5913, 179.5312, 196.1213, 142.2605]) Cost: 0.173442\n",
            "Epoch  800/1000 hypothesis: tensor([152.6257, 184.5921, 179.5372, 196.1161, 142.2647]) Cost: 0.171142\n",
            "Epoch  900/1000 hypothesis: tensor([152.6208, 184.5928, 179.5430, 196.1110, 142.2689]) Cost: 0.168919\n",
            "Epoch 1000/1000 hypothesis: tensor([152.6159, 184.5936, 179.5488, 196.1061, 142.2731]) Cost: 0.166783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CUeGAFObIUBZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}